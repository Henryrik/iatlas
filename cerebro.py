import requests, json, os, re
from googlesearch import search
import trafilatura

DATA_DIR = "data"
os.makedirs(DATA_DIR, exist_ok=True)
MEMORIA_APRENDIZAJE = os.path.join(DATA_DIR, "conocimiento_propio.json")

# üõ°Ô∏è Identificaci√≥n para evitar bloqueos
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

def extraer_entidad(texto):
    t = texto.lower()
    t = re.sub(r"[¬ø?¬°!]", "", t)
    # Mejoramos la limpieza para detectar cuando el usuario pide "m√°s"
    basura = ["sabes", "historia", "de", "los", "las", "el", "la", "sobre", "que", "dime", "cuentame", "extiendete", "mas", "cu√©ntame", "exti√©ndete"]
    palabras = [p for p in t.split() if p not in basura]
    return " ".join(palabras).strip()

def buscar_en_internet(tema, extensa=False):
    """Explora la web y extrae contenido mucho m√°s amplio"""
    try:
        # Si el usuario pide extenderse, usamos palabras clave m√°s potentes
        query = f"{tema} historia completa detalles" if extensa else f"{tema} historia resumen"
        urls = list(search(query, num_results=3, lang="es"))
        
        for url in urls:
            r = requests.get(url, headers=HEADERS, timeout=12)
            if r.status_code == 200:
                # Extraemos con formato y tablas si es posible
                texto = trafilatura.extract(r.text, include_comments=False, include_tables=True)
                if texto and len(texto) > 400:
                    # Si es extensa, devolvemos hasta 3000 caracteres, si no, 800
                    limite = 3000 if extensa else 800
                    return f"{texto[:limite]}...\n\n(Fuente: {url})"
    except Exception as e:
        print(f"Error de exploraci√≥n: {e}")
    return None

def pensar(texto_usuario):
    # Cargar memoria local
    if os.path.exists(MEMORIA_APRENDIZAJE):
        with open(MEMORIA_APRENDIZAJE, "r", encoding="utf-8") as f:
            memoria = json.load(f)
    else: memoria = {}

    # Detectar si el usuario quiere m√°s informaci√≥n
    quiere_mas = any(p in texto_usuario.lower() for p in ["mas", "extiendete", "detalle", "profundiza"])
    entidad = extraer_entidad(texto_usuario)
    
    if not entidad: return "Hola Henry, ¬øsobre qu√© imperio o cultura quieres profundizar hoy?"

    # L√≥gica de b√∫squeda profunda
    if entidad in memoria and not quiere_mas:
        respuesta = memoria[entidad]
    else:
        # Intentar Wikipedia primero (solo si no es un pedido de extensi√≥n profunda)
        respuesta = None
        if not quiere_mas:
            try:
                wiki_url = f"https://es.wikipedia.org/api/rest_v1/page/summary/{entidad.replace(' ', '_')}"
                res = requests.get(wiki_url, headers=HEADERS, timeout=7).json()
                respuesta = res.get("extract")
            except: respuesta = None

        # üöÄ Si Wikipedia no basta o piden "m√°s", navegar por la web real de forma extensa
        if not respuesta or quiere_mas:
            respuesta = buscar_en_internet(entidad, extensa=quiere_mas)

    if respuesta:
        memoria[entidad] = respuesta
        with open(MEMORIA_APRENDIZAJE, "w", encoding="utf-8") as f:
            json.dump(memoria, f, ensure_ascii=False, indent=2)
        
        titulo = f"üìö INVESTIGACI√ìN DETALLADA: {entidad.upper()}" if quiere_mas else f"üåê CONSULTA: {entidad.upper()}"
        return f"**{titulo}**\n\n{respuesta}"
    
    return f"Henry, busqu√© informaci√≥n extensa sobre '{entidad}', pero los sitios est√°n protegidos. ¬øIntentamos con otro tema?"