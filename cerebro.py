import requests, json, os, re
from googlesearch import search
import trafilatura

DATA_DIR = "data"
os.makedirs(DATA_DIR, exist_ok=True)
MEMORIA_APRENDIZAJE = os.path.join(DATA_DIR, "conocimiento_propio.json")

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

def extraer_entidad(texto):
    t = texto.lower()
    t = re.sub(r"[Â¿?Â¡!]", "", t)
    # Limpieza masiva de ruido para encontrar el nÃºcleo del tema
    basura = ["sabes", "historia", "de", "los", "las", "el", "la", "sobre", "que", "dime", "cuentame", "extiendete", "mas", "todo", "detallado", "como", "ocurrio", "disuelva", "desaparecio"]
    palabras = [p for p in t.split() if p not in basura]
    return " ".join(palabras).strip()

def formatear_erudito(texto, entidad):
    """Crea una estructura de reporte ejecutivo con puntos clave"""
    # Limpieza de saltos de lÃ­nea excesivos
    texto_limpio = re.sub(r'\n+', '\n', texto).strip()
    parrafos = [p for p in texto_limpio.split('.') if len(p.strip()) > 40]
    
    # ConstrucciÃ³n de Puntos Clave
    puntos_clave = ""
    for i, p in enumerate(parrafos[:6]):
        puntos_clave += f"ðŸ”¹ {p.strip()}.\n"

    return f"ðŸ›ï¸ **ARCHIVO HISTÃ“RICO: {entidad.upper()}**\n\n" \
           f"âœ… **RESUMEN EJECUTIVO (Puntos Clave):**\n{puntos_clave}\n" \
           f"ðŸ“œ **CRÃ“NICA DETALLADA:**\n{texto_limpio[:4000]}..."

def investigacion_profunda(tema):
    """Navega por mÃºltiples sitios para extraer conocimiento sin lÃ­mites"""
    try:
        # BÃºsqueda ampliada para evitar bloqueos
        consultas = [f"{tema} historia completa detallada", f"por que desaparecio {tema}", f"cronologia de {tema}"]
        conocimiento_acumulado = ""
        
        for q in consultas:
            urls = list(search(q, num_results=3, lang="es"))
            for url in urls:
                try:
                    r = requests.get(url, headers=HEADERS, timeout=15)
                    if r.status_code == 200:
                        contenido = trafilatura.extract(r.text, include_tables=True, include_comments=False)
                        if contenido and len(contenido) > 500:
                            conocimiento_acumulado += f"\n{contenido}\n"
                            if len(conocimiento_acumulado) > 6000: break
                except: continue
            if len(conocimiento_acumulado) > 3000: break
            
        return conocimiento_acumulado if conocimiento_acumulado else None
    except Exception as e:
        print(f"Error en gran archivo: {e}")
        return None

def pensar(texto_usuario):
    if os.path.exists(MEMORIA_APRENDIZAJE):
        with open(MEMORIA_APRENDIZAJE, "r", encoding="utf-8") as f:
            memoria = json.load(f)
    else: memoria = {}

    entidad = extraer_entidad(texto_usuario)
    if not entidad or len(entidad) < 3: 
        return "Hola Henry. Soy IAtlas, tu historiador personal. Â¿QuÃ© civilizaciÃ³n quieres que investigue a fondo?"

    # Iniciamos bÃºsqueda sin lÃ­mites
    info_total = investigacion_profunda(entidad)

    if info_total:
        respuesta_formateada = formatear_erudito(info_total, entidad)
        
        # Guardar aprendizaje
        memoria[entidad] = info_total[:2000]
        with open(MEMORIA_APRENDIZAJE, "w", encoding="utf-8") as f:
            json.dump(memoria, f, ensure_ascii=False, indent=2)
            
        return respuesta_formateada
    
    return f"Henry, he rastreado los archivos sobre '{entidad}' pero los sitios estÃ¡n inaccesibles ahora. Intenta con un tÃ©rmino mÃ¡s general como 'Imperio Inca' o 'Antiguo Egipto'."